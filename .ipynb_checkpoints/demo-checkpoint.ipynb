{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from model.module import FlowMatchingModule\n",
    "from model.cvf import CFGVectorFieldODE\n",
    "from lightning import LightningModule\n",
    "from torchdyn.core import NeuralODE\n",
    "from torch import nn\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "model_path = \"path/to/model.ckpt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Generation Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function for loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_module(model_path: str) -> LightningModule:\n",
    "    \"\"\"\n",
    "    Load the saved model checkpoint for inference\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(model_path):\n",
    "        raise FileNotFoundError(f'Model checkpoint not found: `{model_path}`.')\n",
    "\n",
    "    cfm_module = FlowMatchingModule.load_from_checkpoint(\n",
    "        checkpoint_path=model_path\n",
    "    )\n",
    "    cfm_module.eval()\n",
    "    return cfm_module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load module from run directory\n",
    "cfm_module = load_module(model_path)\n",
    "vector_field = cfm_module.model #learned vector field\n",
    "cond_path = cfm_module.path #Gaussian conditional probability path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vector field wrapper class to simulate vector field with conditional y (required for compatibility with `torchdyn`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorFieldWrapper(nn.Module):\n",
    "    def __init__(self, vf, y):\n",
    "        super().__init__()\n",
    "        self.vf = vf\n",
    "        self.y = y\n",
    "\n",
    "    def forward(self, t, x, **kwargs): #forward method must accept additional keyword arguments\n",
    "        return self.vf(x, t.view(1, -1, 1, 1, 1).expand(len(x), -1, 1, 1, 1), self.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample from simple distribution (Gaussian) and generate images from labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters for generating images\n",
    "num_timesteps = 20\n",
    "samples_per_class = 10\n",
    "guidance_scales = [1.0, 3.0]\n",
    "\n",
    "fig, axes = plt.subplots(1, len(guidance_scales), figsize=(10 * len(guidance_scales), 10))\n",
    "\n",
    "for idx, w in enumerate(guidance_scales):\n",
    "    #define conditional y to guide vector field\n",
    "    y = torch.tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], dtype=torch.int64, device=cfm_module.device).repeat_interleave(samples_per_class)\n",
    "    num_samples = len(y)\n",
    "\n",
    "    #define vector field\n",
    "    vf_ode = CFGVectorFieldODE(vector_field, w)\n",
    "    wrapped_vf = VectorFieldWrapper(vf_ode, y)\n",
    "    flow_ode = NeuralODE(wrapped_vf, sensitivity='adjoint', solver='euler') #try different solvers (euler is fastest)\n",
    "\n",
    "    #define initial state to simulate\n",
    "    x0, _ = cond_path.p_simple.sample(num_samples)\n",
    "\n",
    "    #solve ODE to generate images\n",
    "    with torch.no_grad():\n",
    "        traj = flow_ode.trajectory(\n",
    "            x0,\n",
    "            t_span=torch.linspace(0, 1, num_timesteps, device=cfm_module.device),\n",
    "        )\n",
    "\n",
    "    # Plot\n",
    "    image_np = traj[-1].squeeze(0) #take the last timepoint of the trajectory\n",
    "    grid = make_grid(image_np, nrow=samples_per_class, normalize=True, value_range=(-1,1))\n",
    "    axes[idx].imshow(grid.permute(1, 2, 0).cpu(), cmap=\"gray\")\n",
    "    axes[idx].axis(\"off\")\n",
    "    axes[idx].set_title(f\"Guidance: $w={w:.1f}$\", fontsize=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
