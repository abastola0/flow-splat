{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "nAw61y4urhRN"
   },
   "source": [
    "# **Awesome 1-step MNIST Generation**\n",
    "\n",
    "# 1-step Mean Flows training on MNIST dataset.\n",
    "\n",
    "Authors:\n",
    "\n",
    "**Weijian Luo**, Peking University, https://pkulwj1994.github.io/;\n",
    "\n",
    "**Yifei Wang**, Rice University, https://a-little-hoof.github.io/;\n",
    "\n",
    "**Acknowledgements**: The **Awesome 1-step MNIST Generation** is built on the **Anotated Diffusion Blog**(https://huggingface.co/blog/annotated-diffusion) created by Niels Rogge and Kashif Rasul. We are glad to send our respects and appreciations to them for the awesome codebase on toy diffusion models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "id": "ljIC37UNs6WV",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install -q -U einops datasets matplotlib tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "id": "OE9TnWS_rhRO",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import einsum\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from tqdm import tqdm\n",
    "\n",
    "import math\n",
    "from inspect import isfunction\n",
    "from functools import partial\n",
    "\n",
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "id": "yNx1h53yrhRP",
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (5,5)\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "os.makedirs('save', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "id": "Q-L63GKl9gs4"
   },
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "id": "898L4RwAS05t",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def grid(array, ncols=8):\n",
    "    array = np.pad(array, [(0,0),(1,1),(1,1),(0,0)], 'constant')\n",
    "    nindex, height, width, intensity = array.shape\n",
    "    ncols = min(nindex, ncols)\n",
    "    nrows = (nindex+ncols-1)//ncols\n",
    "    r = nrows*ncols - nindex # remainder\n",
    "    # want result.shape = (height*nrows, width*ncols, intensity)\n",
    "    arr = np.concatenate([array]+[np.zeros([1,height,width,intensity])]*r)\n",
    "    result = (arr.reshape(nrows, ncols, height, width, intensity)\n",
    "              .swapaxes(1,2)\n",
    "              .reshape(height*nrows, width*ncols, intensity))\n",
    "    return np.pad(result, [(1,1),(1,1),(0,0)], 'constant')\n",
    "\n",
    "\n",
    "\n",
    "class NextDataLoader(torch.utils.data.DataLoader):\n",
    "    def __next__(self):\n",
    "        try:\n",
    "            return next(self.iterator)\n",
    "        except:\n",
    "            self.iterator = self.__iter__()\n",
    "            return next(self.iterator)\n",
    "\n",
    "\n",
    "\n",
    "def to_tensor(obj, device='cuda'):\n",
    "    if obj.shape[-1] != 3 and obj.shape[-1] != 1:\n",
    "        obj = np.expand_dims(obj,-1)\n",
    "    if obj.ndim < 4:\n",
    "        obj = np.expand_dims(obj,0)\n",
    "    t = torch.tensor(np.moveaxis(obj,-1,-3), dtype=torch.float, device=device)\n",
    "    return t\n",
    "\n",
    "\n",
    "def to_img(obj):\n",
    "    array = np.moveaxis(obj.data.cpu().numpy(),-3,-1)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {
    "id": "220TYFwRbLwG"
   },
   "source": [
    "## Utility functions for neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "id": "GZ_nckEWrTde",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def exists(x):\n",
    "    return x is not None\n",
    "\n",
    "def default(val, d):\n",
    "    if exists(val):\n",
    "        return val\n",
    "    return d() if isfunction(d) else d\n",
    "\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        return self.fn(x, *args, **kwargs) + x\n",
    "\n",
    "def Upsample(dim):\n",
    "    return nn.ConvTranspose2d(dim, dim, 4, 2, 1)\n",
    "\n",
    "def Downsample(dim):\n",
    "    return nn.Conv2d(dim, dim, 4, 2, 1)\n",
    "\n",
    "class SinusoidalPositionEmbeddings(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, time):\n",
    "        device = time.device\n",
    "        half_dim = self.dim // 2\n",
    "        embeddings = math.log(10000) / (half_dim - 1)\n",
    "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
    "        embeddings = time[:, None] * embeddings[None, :]\n",
    "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
    "        return embeddings\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, dim, dim_out, groups = 8):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Conv2d(dim, dim_out, 3, padding = 1)\n",
    "        self.norm = nn.GroupNorm(groups, dim_out)\n",
    "        self.act = nn.SiLU()\n",
    "\n",
    "    def forward(self, x, scale_shift = None):\n",
    "        x = self.proj(x)\n",
    "        x = self.norm(x)\n",
    "\n",
    "        if exists(scale_shift):\n",
    "            scale, shift = scale_shift\n",
    "            x = x * (scale + 1) + shift\n",
    "\n",
    "        x = self.act(x)\n",
    "        return x\n",
    "\n",
    "class ResnetBlock(nn.Module):\n",
    "    \"\"\"https://arxiv.org/abs/1512.03385\"\"\"\n",
    "\n",
    "    def __init__(self, dim, dim_out, *, time_emb_dim=None, groups=8):\n",
    "        super().__init__()\n",
    "        self.mlp = (\n",
    "            nn.Sequential(nn.SiLU(), nn.Linear(time_emb_dim, dim_out))\n",
    "            if exists(time_emb_dim)\n",
    "            else None\n",
    "        )\n",
    "\n",
    "        self.block1 = Block(dim, dim_out, groups=groups)\n",
    "        self.block2 = Block(dim_out, dim_out, groups=groups)\n",
    "        self.res_conv = nn.Conv2d(dim, dim_out, 1) if dim != dim_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x, time_emb=None):\n",
    "        h = self.block1(x)\n",
    "\n",
    "        if exists(self.mlp) and exists(time_emb):\n",
    "            time_emb = self.mlp(time_emb)\n",
    "            h = rearrange(time_emb, \"b c -> b c 1 1\") + h\n",
    "\n",
    "        h = self.block2(h)\n",
    "        return h + self.res_conv(x)\n",
    "\n",
    "class ConvNextBlock(nn.Module):\n",
    "    \"\"\"https://arxiv.org/abs/2201.03545\"\"\"\n",
    "\n",
    "    def __init__(self, dim, dim_out, *, time_emb_dim=None, mult=2, norm=True):\n",
    "        super().__init__()\n",
    "        self.mlp = (\n",
    "            nn.Sequential(nn.GELU(), nn.Linear(time_emb_dim, dim))\n",
    "            if exists(time_emb_dim)\n",
    "            else None\n",
    "        )\n",
    "\n",
    "        self.ds_conv = nn.Conv2d(dim, dim, 7, padding=3, groups=dim)\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.GroupNorm(1, dim) if norm else nn.Identity(),\n",
    "            nn.Conv2d(dim, dim_out * mult, 3, padding=1),\n",
    "            nn.GELU(),\n",
    "            nn.GroupNorm(1, dim_out * mult),\n",
    "            nn.Conv2d(dim_out * mult, dim_out, 3, padding=1),\n",
    "        )\n",
    "\n",
    "        self.res_conv = nn.Conv2d(dim, dim_out, 1) if dim != dim_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x, time_emb=None):\n",
    "        h = self.ds_conv(x)\n",
    "\n",
    "        if exists(self.mlp) and exists(time_emb):\n",
    "            assert exists(time_emb), \"time embedding must be passed in\"\n",
    "            condition = self.mlp(time_emb)\n",
    "            h = h + rearrange(condition, \"b c -> b c 1 1\")\n",
    "\n",
    "        h = self.net(h)\n",
    "        return h + self.res_conv(x)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, heads=4, dim_head=32):\n",
    "        super().__init__()\n",
    "        self.scale = dim_head**-0.5\n",
    "        self.heads = heads\n",
    "        hidden_dim = dim_head * heads\n",
    "        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias=False)\n",
    "        self.to_out = nn.Conv2d(hidden_dim, dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        qkv = self.to_qkv(x).chunk(3, dim=1)\n",
    "        q, k, v = map(\n",
    "            lambda t: rearrange(t, \"b (h c) x y -> b h c (x y)\", h=self.heads), qkv\n",
    "        )\n",
    "        q = q * self.scale\n",
    "\n",
    "        sim = einsum(\"b h d i, b h d j -> b h i j\", q, k)\n",
    "        sim = sim - sim.amax(dim=-1, keepdim=True).detach()\n",
    "        attn = sim.softmax(dim=-1)\n",
    "\n",
    "        out = einsum(\"b h i j, b h d j -> b h i d\", attn, v)\n",
    "        out = rearrange(out, \"b h (x y) d -> b (h d) x y\", x=h, y=w)\n",
    "        return self.to_out(out)\n",
    "\n",
    "class LinearAttention(nn.Module):\n",
    "    def __init__(self, dim, heads=4, dim_head=32):\n",
    "        super().__init__()\n",
    "        self.scale = dim_head**-0.5\n",
    "        self.heads = heads\n",
    "        hidden_dim = dim_head * heads\n",
    "        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias=False)\n",
    "\n",
    "        self.to_out = nn.Sequential(nn.Conv2d(hidden_dim, dim, 1),\n",
    "                                    nn.GroupNorm(1, dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        qkv = self.to_qkv(x).chunk(3, dim=1)\n",
    "        q, k, v = map(\n",
    "            lambda t: rearrange(t, \"b (h c) x y -> b h c (x y)\", h=self.heads), qkv\n",
    "        )\n",
    "\n",
    "        q = q.softmax(dim=-2)\n",
    "        k = k.softmax(dim=-1)\n",
    "\n",
    "        q = q * self.scale\n",
    "        context = torch.einsum(\"b h d n, b h e n -> b h d e\", k, v)\n",
    "\n",
    "        out = torch.einsum(\"b h d e, b h d n -> b h e n\", context, q)\n",
    "        out = rearrange(out, \"b h c (x y) -> b (h c) x y\", h=self.heads, x=h, y=w)\n",
    "        return self.to_out(out)\n",
    "\n",
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "        self.norm = nn.GroupNorm(1, dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "        return self.fn(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {
    "id": "9E88vnbxBpOI"
   },
   "source": [
    "## Mean Flows\n",
    "Reference paper: [Mean Flows for One-step Generative Modeling](https://arxiv.org/abs/2505.13447).\n",
    "\n",
    "The original method is implemented in jax, we provide a pytorch version."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {
    "id": "_0vwY1BmBpOJ"
   },
   "source": [
    "### Mean Flows model\n",
    "- We modify traditional UNet so that it can accept an additional timestep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "id": "VuIUbPw1rTfm",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Unet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        init_dim=None,\n",
    "        out_dim=None,\n",
    "        dim_mults=(1, 2, 4, 8),\n",
    "        channels=3,\n",
    "        with_time_emb=True,\n",
    "        resnet_block_groups=8,\n",
    "        use_convnext=True,\n",
    "        convnext_mult=2,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # determine dimensions\n",
    "        self.channels = channels\n",
    "\n",
    "        init_dim = default(init_dim, dim // 3 * 2)\n",
    "        self.init_conv = nn.Conv2d(channels, init_dim, 7, padding=3)\n",
    "\n",
    "        dims = [init_dim, *map(lambda m: dim * m, dim_mults)]\n",
    "        in_out = list(zip(dims[:-1], dims[1:]))\n",
    "\n",
    "        if use_convnext:\n",
    "            block_klass = partial(ConvNextBlock, mult=convnext_mult)\n",
    "        else:\n",
    "            block_klass = partial(ResnetBlock, groups=resnet_block_groups)\n",
    "\n",
    "        # time embeddings\n",
    "        if with_time_emb:\n",
    "            time_dim = dim * 4\n",
    "            self.time_mlp = nn.Sequential(\n",
    "                SinusoidalPositionEmbeddings(dim),\n",
    "                nn.Linear(dim, time_dim),\n",
    "                nn.GELU(),\n",
    "                nn.Linear(time_dim, time_dim),\n",
    "            )\n",
    "            self.time_mlp_h = nn.Sequential(\n",
    "                SinusoidalPositionEmbeddings(dim),\n",
    "                nn.Linear(dim, time_dim),\n",
    "                nn.GELU(),\n",
    "                nn.Linear(time_dim, time_dim),\n",
    "            )\n",
    "        else:\n",
    "            time_dim = None\n",
    "            self.time_mlp = None\n",
    "\n",
    "        # layers\n",
    "        self.downs = nn.ModuleList([])\n",
    "        self.ups = nn.ModuleList([])\n",
    "        num_resolutions = len(in_out)\n",
    "\n",
    "        for ind, (dim_in, dim_out) in enumerate(in_out):\n",
    "            is_last = ind >= (num_resolutions - 1)\n",
    "\n",
    "            self.downs.append(\n",
    "                nn.ModuleList(\n",
    "                    [\n",
    "                        block_klass(dim_in, dim_out, time_emb_dim=time_dim),\n",
    "                        block_klass(dim_out, dim_out, time_emb_dim=time_dim),\n",
    "                        Residual(PreNorm(dim_out, LinearAttention(dim_out))),\n",
    "                        Downsample(dim_out) if not is_last else nn.Identity(),\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "\n",
    "        mid_dim = dims[-1]\n",
    "        self.mid_block1 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim)\n",
    "        self.mid_attn = Residual(PreNorm(mid_dim, Attention(mid_dim)))\n",
    "        self.mid_block2 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim)\n",
    "\n",
    "        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):\n",
    "            is_last = ind >= (num_resolutions - 1)\n",
    "\n",
    "            self.ups.append(\n",
    "                nn.ModuleList(\n",
    "                    [\n",
    "                        block_klass(dim_out * 2, dim_in, time_emb_dim=time_dim),\n",
    "                        block_klass(dim_in, dim_in, time_emb_dim=time_dim),\n",
    "                        Residual(PreNorm(dim_in, LinearAttention(dim_in))),\n",
    "                        Upsample(dim_in) if not is_last else nn.Identity(),\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "\n",
    "        out_dim = default(out_dim, channels)\n",
    "        self.final_conv = nn.Sequential(\n",
    "            block_klass(dim, dim), nn.Conv2d(dim, out_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, time, h=None):\n",
    "        x = self.init_conv(x)\n",
    "\n",
    "        t = self.time_mlp(time) if exists(self.time_mlp) else None\n",
    "        # print(f\"t shape: {t.shape if t is not None else 'None'}\")\n",
    "\n",
    "        if h is not None:\n",
    "            # print(f\"h shape: {h.shape}\")\n",
    "            t = t + self.time_mlp_h(h)\n",
    "            # print(f\"t shape after h addition: {t.shape}\")\n",
    "\n",
    "        h_list = []\n",
    "\n",
    "        # downsample\n",
    "        for block1, block2, attn, downsample in self.downs:\n",
    "            x = block1(x, t)\n",
    "            x = block2(x, t)\n",
    "            x = attn(x)\n",
    "            h_list.append(x)\n",
    "            x = downsample(x)\n",
    "\n",
    "        # bottleneck\n",
    "        x = self.mid_block1(x, t)\n",
    "        x = self.mid_attn(x)\n",
    "        x = self.mid_block2(x, t)\n",
    "\n",
    "        # upsample\n",
    "        for block1, block2, attn, upsample in self.ups:\n",
    "            x = torch.cat((x, h_list.pop()), dim=1)\n",
    "            x = block1(x, t)\n",
    "            x = block2(x, t)\n",
    "            x = attn(x)\n",
    "            x = upsample(x)\n",
    "\n",
    "        return self.final_conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {
    "id": "UFCb5vb-BpOK"
   },
   "source": [
    "### Mean Flows loss function\n",
    "- Algorithm 1 in Mean Flows paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "id": "eZ7gTyCEBpOK"
   },
   "outputs": [],
   "source": [
    "class MeanFlowLoss:\n",
    "    def __init__(self, P_mean=-0.4, P_std=1.0,noise_dist='logit_normal', data_proportion=0.75, norm_p=1.0, norm_eps=1.0):\n",
    "        self.P_mean = P_mean\n",
    "        self.P_std = P_std\n",
    "        self.data_proportion = data_proportion\n",
    "        self.norm_p = norm_p\n",
    "        self.norm_eps = norm_eps\n",
    "        self.noise_dist = noise_dist\n",
    "\n",
    "    def _logit_normal_dist(self, shape, device):\n",
    "        rnd_normal = torch.randn(shape, device=device)\n",
    "        return torch.sigmoid(rnd_normal * self.P_std + self.P_mean)\n",
    "\n",
    "    def _uniform_dist(self, shape, device):\n",
    "        return torch.rand(shape, device=device)\n",
    "\n",
    "    def noise_distribution(self, shape, device):\n",
    "        if self.noise_dist == 'logit_normal':\n",
    "            return self._logit_normal_dist(shape, device)\n",
    "        elif self.noise_dist == 'uniform':\n",
    "            return self._uniform_dist(shape, device)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown noise distribution: {self.noise_dist}\")\n",
    "\n",
    "    def __call__(self, net, images):\n",
    "        x = images\n",
    "        device = x.device\n",
    "        batch_size = x.shape[0]\n",
    "        shape = (batch_size, 1, 1, 1)\n",
    "\n",
    "        t = self.noise_distribution(shape, device) # Sample t and r from noise distribution\n",
    "        r = self.noise_distribution(shape, device)\n",
    "        t, r = torch.max(t, r), torch.min(t, r)\n",
    "\n",
    "        zero_mask = torch.arange(batch_size, device=device) < int(batch_size * self.data_proportion)\n",
    "        zero_mask = zero_mask.view(shape)\n",
    "        r = torch.where(zero_mask, t, r)  # Ensure t >= r and apply data proportion\n",
    "\n",
    "        y = x\n",
    "\n",
    "        n = torch.randn_like(y) # Create noise and corrupted image\n",
    "        z_t = (1 - t) * y + t * n\n",
    "        v = n - y  # True velocity\n",
    "\n",
    "        v_g = v\n",
    "\n",
    "        # Compute model output and time derivative\n",
    "        def u_wrapper(z, t, r):\n",
    "            return net(z, t.squeeze(), h=(t-r).squeeze())\n",
    "\n",
    "        primals = (z_t, t, r)\n",
    "        tangents = (v_g, torch.ones_like(t), torch.zeros_like(t))\n",
    "        u, du_dt = torch.func.jvp(u_wrapper, primals, tangents)\n",
    "\n",
    "        u_tgt = v_g - torch.clamp(t - r, min=0.0, max=1.0) * du_dt # Compute target velocity\n",
    "        u_tgt = u_tgt.detach()\n",
    "\n",
    "        unweighted_loss = (u - u_tgt).pow(2).sum(dim=[1, 2, 3]) # Adaptive loss weighting\n",
    "        with torch.no_grad():\n",
    "            adaptive_weight = 1 / (unweighted_loss + self.norm_eps).pow(self.norm_p)\n",
    "\n",
    "        loss = unweighted_loss * adaptive_weight\n",
    "        return loss.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"cuda_available:\", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from gmod.gsplat.project_gaussians_2d_scale_rot import project_gaussians_2d_scale_rot\n",
    "from gmod.gsplat.rasterize_sum import rasterize_gaussians_sum\n",
    "device = torch.device(\"cuda\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N = 25\n",
    "\n",
    "xy = torch.rand(N, 2, device=device, requires_grad=True)                  # center (0~1)\n",
    "scale = torch.full((N, 2), 3.0, device=device, requires_grad=True)       # init node size\n",
    "feat = torch.rand(N, 3, device=device, requires_grad=True)        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render(xy, scale, feat, size):\n",
    "    H, W = size\n",
    "    tile_bounds = (W // 16, H // 16, 1)\n",
    "    rot = torch.zeros(N, 1, device=device, requires_grad=True)                \n",
    "#    xy_pix, radii, conics, num_tiles_hit = project_gaussians_2d_scale_rot(xy, scale, rot, H, W, tile_bounds)\n",
    "    project_gaussians_2d_scale_rot(xy, scale, rot, H, W, tile_bounds)\n",
    "    return\n",
    "\n",
    "    # Render\n",
    "    out = rasterize_gaussians_sum(\n",
    "        xy_pix, radii, conics, num_tiles_hit,\n",
    "        feat, H, W,\n",
    "        BLOCK_H=16, BLOCK_W=16,\n",
    "        topk_norm=True\n",
    "    )\n",
    "    return out\n",
    "\n",
    "render(xy, scale, feat, (32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "H, W = 256, 256\n",
    "tile_bounds = (W // 16, H // 16, 1)\n",
    "rot = torch.zeros(N, 1, device=device, requires_grad=True)    \n",
    "xy_pix, radii, conics, num_tiles_hit = project_gaussians_2d_scale_rot(xy, scale, rot, H, W, tile_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {
    "id": "jlUR6O5XrhRT"
   },
   "source": [
    "### Mean Flows training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "id": "wAmj35rCrhRT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(mf, max_iter, batch_size, mf_opt_args,\n",
    "          num_workers, val_interval, checkpoint=None):\n",
    "\n",
    "    device = 'cuda'\n",
    "\n",
    "    # create dataloader\n",
    "    mean = 0.5\n",
    "    std = 0.5\n",
    "    dataset = MNIST('data', transform=T.Compose([T.ToTensor(), T.Pad(2), T.Normalize((mean,), (std,))]), download=True)\n",
    "    dataloader = NextDataLoader(dataset, batch_size, num_workers=4, prefetch_factor=2, pin_memory=True)\n",
    "\n",
    "    #eval_noise = torch.randn(64,1,32,32).to(device)\n",
    "    # Gaussian Splatting mods\n",
    "    \n",
    "\n",
    "\n",
    "    # create optimizer\n",
    "    mf_optimizer = torch.optim.Adam(mf.parameters(), **mf_opt_args)\n",
    "\n",
    "    mf_loss = MeanFlowLoss()\n",
    "\n",
    "    loss_history = []\n",
    "    mf.train()\n",
    "    for i in tqdm(range(max_iter)):\n",
    "\n",
    "        x0 = next(dataloader)[0].to(device)\n",
    "        print(x0.shape)\n",
    "        print(eval_noise.shape)\n",
    "        break\n",
    "\n",
    "        loss = mf_loss(mf, x0)\n",
    "        loss_history.append(loss.item())\n",
    "\n",
    "        mf_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        mf_optimizer.step()\n",
    "\n",
    "        if i % val_interval == 0:\n",
    "\n",
    "            mf.eval()\n",
    "            with torch.no_grad():\n",
    "                gen_x0 = generate(mf, eval_noise)\n",
    "            mf.train()\n",
    "\n",
    "            display.clear_output(wait=True)\n",
    "\n",
    "\n",
    "            plt.figure(figsize=(5,5))\n",
    "            gen_x0 = gen_x0.detach().permute(0,2,3,1).clamp(-1,1)*std + mean\n",
    "            plt.title('diffusion sample', fontsize=17)\n",
    "            plt.imshow(grid(gen_x0.cpu()).squeeze())\n",
    "            plt.show()\n",
    "\n",
    "            # 2. 实时绘制 loss 曲线\n",
    "            if i != 0:\n",
    "                plt.figure(figsize=(6, 4))\n",
    "                plt.plot(loss_history, label='Training Loss')\n",
    "                plt.title('Loss Curve')\n",
    "                plt.xlabel('Iteration')\n",
    "                plt.ylabel('Loss')\n",
    "                plt.grid(True)\n",
    "                plt.legend()\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "    torch.save({\n",
    "                'mf': mf.state_dict(),\n",
    "    }, 'save/mnist_mf.pt')\n",
    "\n",
    "    print('training ends~ Have a good Day!')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {
    "id": "7LVdSzQABpOL"
   },
   "source": [
    "### Mean Flows generation\n",
    "- Algorithm 2 in Mean Flows paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {
    "id": "7RkUyQ51BpOL"
   },
   "outputs": [],
   "source": [
    "def generate(mf, noise):\n",
    "    B,C,H,W = noise.shape[0], noise.shape[1], noise.shape[2], noise.shape[3]\n",
    "\n",
    "    z = noise\n",
    "    t = torch.ones(B,1,1,1).to(noise.device)\n",
    "    h = torch.ones_like(t)  # Initialize h as ones\n",
    "    x0 = z-mf(noise, t.squeeze(), h.squeeze())\n",
    "\n",
    "    return x0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {
    "id": "Q17S6YFZb4Mm"
   },
   "source": [
    "### Start training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 863,
     "referenced_widgets": [
      "e6556a44eb2847ceb4d444585a331e93",
      "76c6f20e1e79444a84388b1bf3749c2e",
      "be75f75d15134f3983494ed80587b2d9",
      "120f66438e5e4f93b15804dd82f269e7",
      "ad93e51c53364f309c957a99017ece48",
      "62f694ffce3740dcb7630caaa3f58b9b",
      "0f7b1e1361f14367a04c130aa7dcf8f7",
      "1fba5e884b5a4502b04e335d0271ee25",
      "a20774e722394481959aedb2bd096a61",
      "61250198e1ad4b90acfee53d53050e3d",
      "d9b03751461c440ea3daea37567d3f8c"
     ]
    },
    "id": "iPOXOEZSrhRX",
    "outputId": "064a4300-9d7f-4555-ded4-b1df55a60878",
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "train_params = {\n",
    "    'max_iter': 20000,\n",
    "    'batch_size' : 128,\n",
    "    'mf_opt_args' : {'lr' : 0.001, 'betas' : (0.9, 0.99), 'eps' : 1e-08},\n",
    "    'num_workers': 4,\n",
    "    'val_interval': 100}\n",
    "\n",
    "mf = Unet(\n",
    "    dim=32,\n",
    "    channels=1,\n",
    "    dim_mults=(1, 2, 4, )\n",
    ").to(device)\n",
    "\n",
    "train(mf, **train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aaai",
   "language": "python",
   "name": "aaai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
