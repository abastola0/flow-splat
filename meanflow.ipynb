{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "nAw61y4urhRN"
   },
   "source": [
    "# **Awesome 1-step MNIST Generation**\n",
    "\n",
    "# 1-step Mean Flows training on MNIST dataset.\n",
    "\n",
    "Authors:\n",
    "\n",
    "**Weijian Luo**, Peking University, https://pkulwj1994.github.io/;\n",
    "\n",
    "**Yifei Wang**, Rice University, https://a-little-hoof.github.io/;\n",
    "\n",
    "**Acknowledgements**: The **Awesome 1-step MNIST Generation** is built on the **Anotated Diffusion Blog**(https://huggingface.co/blog/annotated-diffusion) created by Niels Rogge and Kashif Rasul. We are glad to send our respects and appreciations to them for the awesome codebase on toy diffusion models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "id": "ljIC37UNs6WV",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install -q -U einops datasets matplotlib tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "id": "OE9TnWS_rhRO",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import einsum\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from tqdm import tqdm\n",
    "\n",
    "import math\n",
    "from inspect import isfunction\n",
    "from functools import partial\n",
    "\n",
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "id": "yNx1h53yrhRP",
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (5,5)\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "os.makedirs('save', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "id": "Q-L63GKl9gs4"
   },
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "id": "898L4RwAS05t",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def grid(array, ncols=8):\n",
    "    array = np.pad(array, [(0,0),(1,1),(1,1),(0,0)], 'constant')\n",
    "    nindex, height, width, intensity = array.shape\n",
    "    ncols = min(nindex, ncols)\n",
    "    nrows = (nindex+ncols-1)//ncols\n",
    "    r = nrows*ncols - nindex # remainder\n",
    "    # want result.shape = (height*nrows, width*ncols, intensity)\n",
    "    arr = np.concatenate([array]+[np.zeros([1,height,width,intensity])]*r)\n",
    "    result = (arr.reshape(nrows, ncols, height, width, intensity)\n",
    "              .swapaxes(1,2)\n",
    "              .reshape(height*nrows, width*ncols, intensity))\n",
    "    return np.pad(result, [(1,1),(1,1),(0,0)], 'constant')\n",
    "\n",
    "\n",
    "\n",
    "class NextDataLoader(torch.utils.data.DataLoader):\n",
    "    def __next__(self):\n",
    "        try:\n",
    "            return next(self.iterator)\n",
    "        except:\n",
    "            self.iterator = self.__iter__()\n",
    "            return next(self.iterator)\n",
    "\n",
    "\n",
    "\n",
    "def to_tensor(obj, device='cuda'):\n",
    "    if obj.shape[-1] != 3 and obj.shape[-1] != 1:\n",
    "        obj = np.expand_dims(obj,-1)\n",
    "    if obj.ndim < 4:\n",
    "        obj = np.expand_dims(obj,0)\n",
    "    t = torch.tensor(np.moveaxis(obj,-1,-3), dtype=torch.float, device=device)\n",
    "    return t\n",
    "\n",
    "\n",
    "def to_img(obj):\n",
    "    array = np.moveaxis(obj.data.cpu().numpy(),-3,-1)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {
    "id": "220TYFwRbLwG"
   },
   "source": [
    "## Utility functions for neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "id": "GZ_nckEWrTde",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def exists(x):\n",
    "    return x is not None\n",
    "\n",
    "def default(val, d):\n",
    "    if exists(val):\n",
    "        return val\n",
    "    return d() if isfunction(d) else d\n",
    "\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        return self.fn(x, *args, **kwargs) + x\n",
    "\n",
    "def Upsample(dim):\n",
    "    return nn.ConvTranspose2d(dim, dim, 4, 2, 1)\n",
    "\n",
    "def Downsample(dim):\n",
    "    return nn.Conv2d(dim, dim, 4, 2, 1)\n",
    "\n",
    "class SinusoidalPositionEmbeddings(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, time):\n",
    "        device = time.device\n",
    "        half_dim = self.dim // 2\n",
    "        embeddings = math.log(10000) / (half_dim - 1)\n",
    "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
    "        embeddings = time[:, None] * embeddings[None, :]\n",
    "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
    "        return embeddings\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, dim, dim_out, groups = 8):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Conv2d(dim, dim_out, 3, padding = 1)\n",
    "        self.norm = nn.GroupNorm(groups, dim_out)\n",
    "        self.act = nn.SiLU()\n",
    "\n",
    "    def forward(self, x, scale_shift = None):\n",
    "        x = self.proj(x)\n",
    "        x = self.norm(x)\n",
    "\n",
    "        if exists(scale_shift):\n",
    "            scale, shift = scale_shift\n",
    "            x = x * (scale + 1) + shift\n",
    "\n",
    "        x = self.act(x)\n",
    "        return x\n",
    "\n",
    "class ResnetBlock(nn.Module):\n",
    "    \"\"\"https://arxiv.org/abs/1512.03385\"\"\"\n",
    "\n",
    "    def __init__(self, dim, dim_out, *, time_emb_dim=None, groups=8):\n",
    "        super().__init__()\n",
    "        self.mlp = (\n",
    "            nn.Sequential(nn.SiLU(), nn.Linear(time_emb_dim, dim_out))\n",
    "            if exists(time_emb_dim)\n",
    "            else None\n",
    "        )\n",
    "\n",
    "        self.block1 = Block(dim, dim_out, groups=groups)\n",
    "        self.block2 = Block(dim_out, dim_out, groups=groups)\n",
    "        self.res_conv = nn.Conv2d(dim, dim_out, 1) if dim != dim_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x, time_emb=None):\n",
    "        h = self.block1(x)\n",
    "\n",
    "        if exists(self.mlp) and exists(time_emb):\n",
    "            time_emb = self.mlp(time_emb)\n",
    "            h = rearrange(time_emb, \"b c -> b c 1 1\") + h\n",
    "\n",
    "        h = self.block2(h)\n",
    "        return h + self.res_conv(x)\n",
    "\n",
    "class ConvNextBlock(nn.Module):\n",
    "    \"\"\"https://arxiv.org/abs/2201.03545\"\"\"\n",
    "\n",
    "    def __init__(self, dim, dim_out, *, time_emb_dim=None, mult=2, norm=True):\n",
    "        super().__init__()\n",
    "        self.mlp = (\n",
    "            nn.Sequential(nn.GELU(), nn.Linear(time_emb_dim, dim))\n",
    "            if exists(time_emb_dim)\n",
    "            else None\n",
    "        )\n",
    "\n",
    "        self.ds_conv = nn.Conv2d(dim, dim, 7, padding=3, groups=dim)\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.GroupNorm(1, dim) if norm else nn.Identity(),\n",
    "            nn.Conv2d(dim, dim_out * mult, 3, padding=1),\n",
    "            nn.GELU(),\n",
    "            nn.GroupNorm(1, dim_out * mult),\n",
    "            nn.Conv2d(dim_out * mult, dim_out, 3, padding=1),\n",
    "        )\n",
    "\n",
    "        self.res_conv = nn.Conv2d(dim, dim_out, 1) if dim != dim_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x, time_emb=None):\n",
    "        h = self.ds_conv(x)\n",
    "\n",
    "        if exists(self.mlp) and exists(time_emb):\n",
    "            assert exists(time_emb), \"time embedding must be passed in\"\n",
    "            condition = self.mlp(time_emb)\n",
    "            h = h + rearrange(condition, \"b c -> b c 1 1\")\n",
    "\n",
    "        h = self.net(h)\n",
    "        return h + self.res_conv(x)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, heads=4, dim_head=32):\n",
    "        super().__init__()\n",
    "        self.scale = dim_head**-0.5\n",
    "        self.heads = heads\n",
    "        hidden_dim = dim_head * heads\n",
    "        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias=False)\n",
    "        self.to_out = nn.Conv2d(hidden_dim, dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        qkv = self.to_qkv(x).chunk(3, dim=1)\n",
    "        q, k, v = map(\n",
    "            lambda t: rearrange(t, \"b (h c) x y -> b h c (x y)\", h=self.heads), qkv\n",
    "        )\n",
    "        q = q * self.scale\n",
    "\n",
    "        sim = einsum(\"b h d i, b h d j -> b h i j\", q, k)\n",
    "        sim = sim - sim.amax(dim=-1, keepdim=True).detach()\n",
    "        attn = sim.softmax(dim=-1)\n",
    "\n",
    "        out = einsum(\"b h i j, b h d j -> b h i d\", attn, v)\n",
    "        out = rearrange(out, \"b h (x y) d -> b (h d) x y\", x=h, y=w)\n",
    "        return self.to_out(out)\n",
    "\n",
    "class LinearAttention(nn.Module):\n",
    "    def __init__(self, dim, heads=4, dim_head=32):\n",
    "        super().__init__()\n",
    "        self.scale = dim_head**-0.5\n",
    "        self.heads = heads\n",
    "        hidden_dim = dim_head * heads\n",
    "        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias=False)\n",
    "\n",
    "        self.to_out = nn.Sequential(nn.Conv2d(hidden_dim, dim, 1),\n",
    "                                    nn.GroupNorm(1, dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        qkv = self.to_qkv(x).chunk(3, dim=1)\n",
    "        q, k, v = map(\n",
    "            lambda t: rearrange(t, \"b (h c) x y -> b h c (x y)\", h=self.heads), qkv\n",
    "        )\n",
    "\n",
    "        q = q.softmax(dim=-2)\n",
    "        k = k.softmax(dim=-1)\n",
    "\n",
    "        q = q * self.scale\n",
    "        context = torch.einsum(\"b h d n, b h e n -> b h d e\", k, v)\n",
    "\n",
    "        out = torch.einsum(\"b h d e, b h d n -> b h e n\", context, q)\n",
    "        out = rearrange(out, \"b h c (x y) -> b (h c) x y\", h=self.heads, x=h, y=w)\n",
    "        return self.to_out(out)\n",
    "\n",
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "        self.norm = nn.GroupNorm(1, dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "        return self.fn(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {
    "id": "9E88vnbxBpOI"
   },
   "source": [
    "## Mean Flows\n",
    "Reference paper: [Mean Flows for One-step Generative Modeling](https://arxiv.org/abs/2505.13447).\n",
    "\n",
    "The original method is implemented in jax, we provide a pytorch version."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {
    "id": "_0vwY1BmBpOJ"
   },
   "source": [
    "### Mean Flows model\n",
    "- We modify traditional UNet so that it can accept an additional timestep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "id": "VuIUbPw1rTfm",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Unet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        init_dim=None,\n",
    "        out_dim=None,\n",
    "        dim_mults=(1, 2, 4, 8),\n",
    "        channels=3,\n",
    "        with_time_emb=True,\n",
    "        resnet_block_groups=8,\n",
    "        use_convnext=True,\n",
    "        convnext_mult=2,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # determine dimensions\n",
    "        self.channels = channels\n",
    "\n",
    "        init_dim = default(init_dim, dim // 3 * 2)\n",
    "        self.init_conv = nn.Conv2d(channels, init_dim, 7, padding=3)\n",
    "\n",
    "        dims = [init_dim, *map(lambda m: dim * m, dim_mults)]\n",
    "        in_out = list(zip(dims[:-1], dims[1:]))\n",
    "\n",
    "        if use_convnext:\n",
    "            block_klass = partial(ConvNextBlock, mult=convnext_mult)\n",
    "        else:\n",
    "            block_klass = partial(ResnetBlock, groups=resnet_block_groups)\n",
    "\n",
    "        # time embeddings\n",
    "        if with_time_emb:\n",
    "            time_dim = dim * 4\n",
    "            self.time_mlp = nn.Sequential(\n",
    "                SinusoidalPositionEmbeddings(dim),\n",
    "                nn.Linear(dim, time_dim),\n",
    "                nn.GELU(),\n",
    "                nn.Linear(time_dim, time_dim),\n",
    "            )\n",
    "            self.time_mlp_h = nn.Sequential(\n",
    "                SinusoidalPositionEmbeddings(dim),\n",
    "                nn.Linear(dim, time_dim),\n",
    "                nn.GELU(),\n",
    "                nn.Linear(time_dim, time_dim),\n",
    "            )\n",
    "        else:\n",
    "            time_dim = None\n",
    "            self.time_mlp = None\n",
    "\n",
    "        # layers\n",
    "        self.downs = nn.ModuleList([])\n",
    "        self.ups = nn.ModuleList([])\n",
    "        num_resolutions = len(in_out)\n",
    "\n",
    "        for ind, (dim_in, dim_out) in enumerate(in_out):\n",
    "            is_last = ind >= (num_resolutions - 1)\n",
    "\n",
    "            self.downs.append(\n",
    "                nn.ModuleList(\n",
    "                    [\n",
    "                        block_klass(dim_in, dim_out, time_emb_dim=time_dim),\n",
    "                        block_klass(dim_out, dim_out, time_emb_dim=time_dim),\n",
    "                        Residual(PreNorm(dim_out, LinearAttention(dim_out))),\n",
    "                        Downsample(dim_out) if not is_last else nn.Identity(),\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "\n",
    "        mid_dim = dims[-1]\n",
    "        self.mid_block1 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim)\n",
    "        self.mid_attn = Residual(PreNorm(mid_dim, Attention(mid_dim)))\n",
    "        self.mid_block2 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim)\n",
    "\n",
    "        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):\n",
    "            is_last = ind >= (num_resolutions - 1)\n",
    "\n",
    "            self.ups.append(\n",
    "                nn.ModuleList(\n",
    "                    [\n",
    "                        block_klass(dim_out * 2, dim_in, time_emb_dim=time_dim),\n",
    "                        block_klass(dim_in, dim_in, time_emb_dim=time_dim),\n",
    "                        Residual(PreNorm(dim_in, LinearAttention(dim_in))),\n",
    "                        Upsample(dim_in) if not is_last else nn.Identity(),\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "\n",
    "        out_dim = default(out_dim, channels)\n",
    "        self.final_conv = nn.Sequential(\n",
    "            block_klass(dim, dim), nn.Conv2d(dim, out_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, time, h=None):\n",
    "        x = self.init_conv(x)\n",
    "\n",
    "        t = self.time_mlp(time) if exists(self.time_mlp) else None\n",
    "        # print(f\"t shape: {t.shape if t is not None else 'None'}\")\n",
    "\n",
    "        if h is not None:\n",
    "            # print(f\"h shape: {h.shape}\")\n",
    "            t = t + self.time_mlp_h(h)\n",
    "            # print(f\"t shape after h addition: {t.shape}\")\n",
    "\n",
    "        h_list = []\n",
    "\n",
    "        # downsample\n",
    "        for block1, block2, attn, downsample in self.downs:\n",
    "            x = block1(x, t)\n",
    "            x = block2(x, t)\n",
    "            x = attn(x)\n",
    "            h_list.append(x)\n",
    "            x = downsample(x)\n",
    "\n",
    "        # bottleneck\n",
    "        x = self.mid_block1(x, t)\n",
    "        x = self.mid_attn(x)\n",
    "        x = self.mid_block2(x, t)\n",
    "\n",
    "        # upsample\n",
    "        for block1, block2, attn, upsample in self.ups:\n",
    "            x = torch.cat((x, h_list.pop()), dim=1)\n",
    "            x = block1(x, t)\n",
    "            x = block2(x, t)\n",
    "            x = attn(x)\n",
    "            x = upsample(x)\n",
    "\n",
    "        return self.final_conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {
    "id": "UFCb5vb-BpOK"
   },
   "source": [
    "### Mean Flows loss function\n",
    "- Algorithm 1 in Mean Flows paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "id": "eZ7gTyCEBpOK"
   },
   "outputs": [],
   "source": [
    "class MeanFlowLoss:\n",
    "    def __init__(self, P_mean=-0.4, P_std=1.0,noise_dist='logit_normal', data_proportion=0.75, norm_p=1.0, norm_eps=1.0):\n",
    "        self.P_mean = P_mean\n",
    "        self.P_std = P_std\n",
    "        self.data_proportion = data_proportion\n",
    "        self.norm_p = norm_p\n",
    "        self.norm_eps = norm_eps\n",
    "        self.noise_dist = noise_dist\n",
    "\n",
    "    def _logit_normal_dist(self, shape, device):\n",
    "        rnd_normal = torch.randn(shape, device=device)\n",
    "        return torch.sigmoid(rnd_normal * self.P_std + self.P_mean)\n",
    "\n",
    "    def _uniform_dist(self, shape, device):\n",
    "        return torch.rand(shape, device=device)\n",
    "\n",
    "    def noise_distribution(self, shape, device):\n",
    "        if self.noise_dist == 'logit_normal':\n",
    "            return self._logit_normal_dist(shape, device)\n",
    "        elif self.noise_dist == 'uniform':\n",
    "            return self._uniform_dist(shape, device)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown noise distribution: {self.noise_dist}\")\n",
    "\n",
    "    def __call__(self, net, images):\n",
    "        x = images\n",
    "        device = x.device\n",
    "        batch_size = x.shape[0]\n",
    "        shape = (batch_size, 1, 1, 1)\n",
    "\n",
    "        t = self.noise_distribution(shape, device) # Sample t and r from noise distribution\n",
    "        r = self.noise_distribution(shape, device)\n",
    "        t, r = torch.max(t, r), torch.min(t, r)\n",
    "\n",
    "        zero_mask = torch.arange(batch_size, device=device) < int(batch_size * self.data_proportion)\n",
    "        zero_mask = zero_mask.view(shape)\n",
    "        r = torch.where(zero_mask, t, r)  # Ensure t >= r and apply data proportion\n",
    "\n",
    "        y = x\n",
    "\n",
    "        n = torch.randn_like(y) # Create noise and corrupted image\n",
    "        z_t = (1 - t) * y + t * n\n",
    "        v = n - y  # True velocity\n",
    "\n",
    "        v_g = v\n",
    "\n",
    "        # Compute model output and time derivative\n",
    "        def u_wrapper(z, t, r):\n",
    "            return net(z, t.squeeze(), h=(t-r).squeeze())\n",
    "\n",
    "        primals = (z_t, t, r)\n",
    "        tangents = (v_g, torch.ones_like(t), torch.zeros_like(t))\n",
    "        u, du_dt = torch.func.jvp(u_wrapper, primals, tangents)\n",
    "\n",
    "        u_tgt = v_g - torch.clamp(t - r, min=0.0, max=1.0) * du_dt # Compute target velocity\n",
    "        u_tgt = u_tgt.detach()\n",
    "\n",
    "        unweighted_loss = (u - u_tgt).pow(2).sum(dim=[1, 2, 3]) # Adaptive loss weighting\n",
    "        with torch.no_grad():\n",
    "            adaptive_weight = 1 / (unweighted_loss + self.norm_eps).pow(self.norm_p)\n",
    "\n",
    "        loss = unweighted_loss * adaptive_weight\n",
    "        return loss.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"cuda_available:\", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xy = torch.rand(N, 2, device=device, requires_grad=True)                  # center (0~1)\n",
    "# scale = torch.full((N, 2), 3.0, device=device, requires_grad=True)       # init node size\n",
    "# feat = torch.rand(N, 1, device=device, requires_grad=True)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42096d05-dc0c-4861-a408-7f14015f9e87",
   "metadata": {},
   "source": [
    "# Gaussian Splatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x773624b1a6d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from gmod.gsplat.project_gaussians_2d_scale_rot import project_gaussians_2d_scale_rot\n",
    "from gmod.gsplat.rasterize_sum import rasterize_gaussians_sum\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "def render(features, size = (32, 32)):\n",
    "    xy = features[:, 0:2]\n",
    "    scale = features[:, 2:3]\n",
    "    feat = features[:, 3:-1]\n",
    "    rot = features[:, -1]\n",
    "    B, N = features.shape[0:2]\n",
    "    H, W = size\n",
    "    tile_bounds = (W // 16, H // 16, 1)\n",
    "    xy_pix, radii, conics, num_tiles_hit = project_gaussians_2d_scale_rot(xy, scale, rot, H, W, tile_bounds)\n",
    "    out = rasterize_gaussians_sum(\n",
    "        xy_pix, radii, conics, num_tiles_hit,\n",
    "        feat, H, W,\n",
    "        BLOCK_H=16, BLOCK_W=16,\n",
    "        topk_norm=True\n",
    "    )\n",
    "    return out\n",
    "\n",
    "# op = render(xy, scale, feat, (32, 32))\n",
    "N = 10\n",
    "op = render(torch.rand(N, 6).to(device))\n",
    "plt.imshow(op[...,0].detach().cpu(), cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">gsplat: CUDA extension already built. Loading from /home/abastol/.cache/torch_extensions/py311_cu124/gsplat_cuda.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mgsplat: CUDA extension already built. Loading from \u001b[0m\u001b[33m/home/abastol/.cache/torch_extensions/py311_cu124/\u001b[0m\u001b[33mgsplat_cuda.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x773626c7cd10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {
    "id": "jlUR6O5XrhRT"
   },
   "source": [
    "### Mean Flows training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "id": "wAmj35rCrhRT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(mf, max_iter, batch_size, mf_opt_args,\n",
    "          num_workers, val_interval, checkpoint=None):\n",
    "\n",
    "    device = 'cuda'\n",
    "\n",
    "    # create dataloader\n",
    "    mean = 0.5\n",
    "    std = 0.5\n",
    "    dataset = MNIST('data', transform=T.Compose([T.ToTensor(), T.Pad(2), T.Normalize((mean,), (std,))]), download=True)\n",
    "    dataloader = NextDataLoader(dataset, batch_size, num_workers=4, prefetch_factor=2, pin_memory=True)\n",
    "\n",
    "    #eval_noise = torch.randn(64,1,32,32).to(device)\n",
    "    # Gaussian Splatting mods\n",
    "    \n",
    "\n",
    "\n",
    "    # create optimizer\n",
    "    mf_optimizer = torch.optim.Adam(mf.parameters(), **mf_opt_args)\n",
    "\n",
    "    mf_loss = MeanFlowLoss()\n",
    "\n",
    "    loss_history = []\n",
    "    mf.train()\n",
    "    for i in tqdm(range(max_iter)):\n",
    "\n",
    "        x0 = next(dataloader)[0].to(device)\n",
    "        print(x0.shape)\n",
    "        print(eval_noise.shape)\n",
    "        break\n",
    "\n",
    "        loss = mf_loss(mf, x0)\n",
    "        loss_history.append(loss.item())\n",
    "\n",
    "        mf_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        mf_optimizer.step()\n",
    "\n",
    "        if i % val_interval == 0:\n",
    "\n",
    "            mf.eval()\n",
    "            with torch.no_grad():\n",
    "                gen_x0 = generate(mf, eval_noise)\n",
    "            mf.train()\n",
    "\n",
    "            display.clear_output(wait=True)\n",
    "\n",
    "\n",
    "            plt.figure(figsize=(5,5))\n",
    "            gen_x0 = gen_x0.detach().permute(0,2,3,1).clamp(-1,1)*std + mean\n",
    "            plt.title('diffusion sample', fontsize=17)\n",
    "            plt.imshow(grid(gen_x0.cpu()).squeeze())\n",
    "            plt.show()\n",
    "\n",
    "            # 2. 实时绘制 loss 曲线\n",
    "            if i != 0:\n",
    "                plt.figure(figsize=(6, 4))\n",
    "                plt.plot(loss_history, label='Training Loss')\n",
    "                plt.title('Loss Curve')\n",
    "                plt.xlabel('Iteration')\n",
    "                plt.ylabel('Loss')\n",
    "                plt.grid(True)\n",
    "                plt.legend()\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "    torch.save({\n",
    "                'mf': mf.state_dict(),\n",
    "    }, 'save/mnist_mf.pt')\n",
    "\n",
    "    print('training ends~ Have a good Day!')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {
    "id": "7LVdSzQABpOL"
   },
   "source": [
    "### Mean Flows generation\n",
    "- Algorithm 2 in Mean Flows paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {
    "id": "7RkUyQ51BpOL"
   },
   "outputs": [],
   "source": [
    "def generate(mf, noise):\n",
    "    B,C,H,W = noise.shape[0], noise.shape[1], noise.shape[2], noise.shape[3]\n",
    "\n",
    "    z = noise\n",
    "    t = torch.ones(B,1,1,1).to(noise.device)\n",
    "    h = torch.ones_like(t)  # Initialize h as ones\n",
    "    x0 = z-mf(noise, t.squeeze(), h.squeeze())\n",
    "\n",
    "    return x0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {
    "id": "Q17S6YFZb4Mm"
   },
   "source": [
    "### Start training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 863,
     "referenced_widgets": [
      "e6556a44eb2847ceb4d444585a331e93",
      "76c6f20e1e79444a84388b1bf3749c2e",
      "be75f75d15134f3983494ed80587b2d9",
      "120f66438e5e4f93b15804dd82f269e7",
      "ad93e51c53364f309c957a99017ece48",
      "62f694ffce3740dcb7630caaa3f58b9b",
      "0f7b1e1361f14367a04c130aa7dcf8f7",
      "1fba5e884b5a4502b04e335d0271ee25",
      "a20774e722394481959aedb2bd096a61",
      "61250198e1ad4b90acfee53d53050e3d",
      "d9b03751461c440ea3daea37567d3f8c"
     ]
    },
    "id": "iPOXOEZSrhRX",
    "outputId": "064a4300-9d7f-4555-ded4-b1df55a60878",
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "train_params = {\n",
    "    'max_iter': 20000,\n",
    "    'batch_size' : 128,\n",
    "    'mf_opt_args' : {'lr' : 0.001, 'betas' : (0.9, 0.99), 'eps' : 1e-08},\n",
    "    'num_workers': 4,\n",
    "    'val_interval': 100}\n",
    "\n",
    "mf = Unet(\n",
    "    dim=32,\n",
    "    channels=1,\n",
    "    dim_mults=(1, 2, 4, )\n",
    ").to(device)\n",
    "\n",
    "train(mf, **train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
